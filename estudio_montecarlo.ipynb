{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/Andrew-mcArty/RL_AAPGAB/blob/main/estudio_montecarlo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://raw.githubusercontent.com/Andrew-mcArty/RL_AAPGAB/refs/heads/main/src/FrozenAgent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'FrozenAgent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mFrozenAgent\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'FrozenAgent'"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import gymnasium as gym\n",
    "import FrozenAgent\n",
    "import random\n",
    "import time\n",
    "\n",
    "semilla=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definimos el entorno:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"definimos el entorno:\")\n",
    "name = 'FrozenLake-v1'\n",
    "env4 = gym.make(name, is_slippery=False, map_name=\"4x4\", render_mode=\"ansi\") # No resbaladizo para entender mejor los resultados.\n",
    "env8 = gym.make(name, is_slippery=False, map_name=\"8x8\", render_mode=\"ansi\") # No resbaladizo para entender mejor los resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función útil para establecer la semilla tanto en numpy como en la librería random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setSemilla(semilla):\n",
    "    random.seed(semilla)\n",
    "    np.random.seed(semilla)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorimto genérico de para evaluar un agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_agent(agent, env, num_episodes=5000, decay=False, semilla=1):\n",
    "    agent.initAgent()\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        state, info = env.reset(seed=semilla)\n",
    "        done = False\n",
    "    \n",
    "        start_time=time.time_ns()\n",
    "        #inicializo el episodio\n",
    "        agent.initEpisode()\n",
    "    \n",
    "        # play one episode\n",
    "        while not done:\n",
    "            if decay:\n",
    "                agent.decay_epsilon()\n",
    "            action = agent.get_action(env, state)\n",
    "            \n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            # update the agent\n",
    "            agent.updateStep(state, action, reward, terminated, next_state)\n",
    "            \n",
    "            # update if the environment is done and the current state\n",
    "            done = terminated or truncated\n",
    "            state = next_state\n",
    "            \n",
    "        #después de acabar el episodio actualizo la Q y el epsilon\n",
    "        agent.updateEpisode()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra los resultados recogidos por el agente durante su entrenamiento. Esta función muestra dos indicadores que implementan todos los agentes: \n",
    "* proporción de recompensas: suma recompensas / episodios\n",
    "* proporción de tamaño de episodios: suma len(episodio) / episodios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot(agent):\n",
    "  # Creamos una lista de índices para el eje x\n",
    "  indices = list(range(len(agent.list_stats)))\n",
    "  \n",
    "  \n",
    "  # Crear figura con dos subgráficos\n",
    "  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "  # Primer subplot\n",
    "  ax1.plot(indices, agent.list_stats, label='stats')\n",
    "  ax1.set_title('Proporción de recompensas')\n",
    "  ax1.set_xlabel('Episodio')\n",
    "  ax1.set_ylabel('Proporción')\n",
    "  ax1.legend()\n",
    "  ax1.grid(True)\n",
    "\n",
    "  # Segundo subplot\n",
    "  ax2.plot(indices, agent.list_episodes, label='episodios')\n",
    "  ax2.set_title('Tamaño de episodios')\n",
    "  ax2.set_xlabel('Episodio')\n",
    "  ax2.set_ylabel('Tamaño')\n",
    "  ax2.legend()\n",
    "  ax2.grid(True)\n",
    "\n",
    "  # Ajustar diseño y mostrar gráfico\n",
    "  plt.tight_layout()\n",
    "  plt.show()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos dos agentes: MC on policy all visits y first visit.\n",
    "\n",
    "Ejecutamos en entrenameiento y obtenemos la mejor política de cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1869.78it/s]\n",
      "100%|██████████| 5000/5000 [00:02<00:00, 1945.39it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#inicializo los numeros aleatorios\n",
    "setSemilla(semilla)\n",
    "\n",
    "# hyperparameters\n",
    "n_episodes = 5000\n",
    "start_epsilon = 0.1\n",
    "discount_factor = 0.99\n",
    "\n",
    "agent1 = FrozenAgent.FrozenAgentMC_On_All(\n",
    "    env=env4,\n",
    "    epsilon=start_epsilon,\n",
    "    discount_factor=discount_factor,\n",
    ")\n",
    "agent2 = FrozenAgent.FrozenAgentMC_On_First(\n",
    "    env=env4,\n",
    "    epsilon=start_epsilon,\n",
    "    discount_factor=discount_factor,\n",
    ")\n",
    "\n",
    "train_agent(agent1, env4, num_episodes=n_episodes, decay=False, semilla=semilla)\n",
    "train_agent(agent2, env4, num_episodes=n_episodes, decay=False, semilla=semilla)\n",
    "\n",
    "pi1, actions1 = agent1.pi_star_from_Q(env4, agent1.Q)\n",
    "pi2, actions2 = agent2.pi_star_from_Q(env4, agent2.Q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FrozenAgentMC_On_All' object has no attribute 'descripcion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m================== AGENTE 1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43magent1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescripcion\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m plot(agent1)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMáxima proporcion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent1\u001b[38;5;241m.\u001b[39mlist_stats[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FrozenAgentMC_On_All' object has no attribute 'descripcion'"
     ]
    }
   ],
   "source": [
    "print(f\"================== AGENTE 1 {agent1.descripcion}\")\n",
    "plot(agent1)\n",
    "print(f\"Máxima proporcion: {agent1.list_stats[-1]}\")\n",
    "print(\"Valores Q para cada estado:\\n\", agent1.Q)\n",
    "print(\"Política óptima obtenida\\n\", pi1, f\"\\n Acciones {actions1} \\n Para el siguiente grid\\n\", env4.render())\n",
    "print()\n",
    "\n",
    "print(f\"================== AGENTE 2 {agent2.descripcion}\")\n",
    "plot(agent2)\n",
    "print(f\"Máxima proporcion: {agent2.list_stats[-1]}\")\n",
    "print(\"Valores Q para cada estado:\\n\", agent2.Q)\n",
    "print(\"Política óptima obtenida\\n\", pi2, f\"\\n Acciones {actions2} \\n Para el siguiente grid\\n\", env4.render())\n",
    "print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
